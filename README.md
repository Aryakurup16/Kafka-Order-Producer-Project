# Kafka Order Producer Project

## ğŸ“Œ Project Overview

This project demonstrates a **basic Apache Kafka setup using Docker** where a **Python producer sends order data** to a Kafka topic and a **Python consumer reads and displays the stored messages**. The project is useful for beginners learning **Kafka, Docker, and event-driven data pipelines**.

The project stores order events such as **user name, item name, quantity, and order ID** using Kafka.

---

## ğŸ—ï¸ Architecture

1. **Kafka Broker** â€“ Runs inside Docker
2. **Producer (producer.py)** â€“ Sends order messages to Kafka topic
3. **Consumer (tracker.py)** â€“ Reads and displays order messages
4. **Docker Compose** â€“ Manages Kafka service

---

## ğŸ“‚ Project Structure

```
StreamStore/
â”œâ”€â”€ docker-compose.yaml
â”œâ”€â”€ producer.py
â”œâ”€â”€ tracker.py
â”œâ”€â”€ myenv/               # Python virtual environment
â””â”€â”€ README.md
```

---

## âš™ï¸ Prerequisites

Make sure you have the following installed:

* Ubuntu / WSL (Linux)
* Python 3.8+
* Docker & Docker Compose
* pip

---

## ğŸ Python Dependencies

Install required Kafka library:

```bash
pip install confluent-kafka
```

---

## ğŸ³ Kafka Setup Using Docker

Start Kafka using Docker Compose:

```bash
docker compose up -d
```

Kafka will start on:

```text
localhost:9092
```

---

## ğŸ§¾ Kafka Topic

The project uses a topic named:

```text
orders
```

(Topic is auto-created if Kafka auto topic creation is enabled)

---

## ğŸš€ Producer Details (producer.py)

The producer:

* Generates a unique `order_id` using UUID
* Sends order details as JSON
* Uses `order_id` as Kafka message key

### Sample Data Sent

```json
{
  "order_id": "uuid",
  "user": "Uday",
  "item": "mobile",
  "quantity": 5
}
```

### Run Producer

```bash
python producer.py
```

---

## ğŸ“¥ Consumer Details (tracker.py)

The consumer:

* Subscribes to the `orders` topic
* Reads messages from the beginning
* Prints order details in readable format

### Run Consumer

```bash
python tracker.py
```

### Sample Output

```text
Received Order ID: xxx
User: Uday
Item: mobile
Quantity: 5
```

---

## ğŸ” Data Flow

1. Producer sends order event to Kafka
2. Kafka stores the message
3. Consumer reads the stored message
4. Order data is displayed in terminal

---

## ğŸ›‘ Stop Kafka

```bash
docker compose down
```

---

## ğŸ“ Key Learning Outcomes

* Kafka Producer and Consumer basics
* Message key and value usage
* Docker-based Kafka setup
* JSON-based message streaming
* Event-driven architecture concept

---

## ğŸ“Œ Use Cases

* Order tracking systems
* Event streaming
* Real-time data pipelines
* Microservices communication

---

## âœ… Conclusion

This project provides a **clean and beginner-friendly Kafka example** to understand how producers and consumers interact using Docker and Python. It can be extended to real-world data engineering and streaming applications.

---

ğŸ“¦ **Author**: Arya Kurup
ğŸ“… **Project Type**: Kafka Learning Project
ğŸš€ **Status**: Working & Ready for Extension
